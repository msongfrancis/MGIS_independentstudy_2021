{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Classify - Census Tracts\n",
    "\n",
    "This script explores different machine learning regressions to predict total e-scooter trip counts for census tracts in Minneapolis MN. The demographic data are from ACS-surveys for 2014-2018, and 2015-2019. The regressions explored are Random Forest, Linear, Ridge and Poisson regression\n",
    "\n",
    "The script requires sklearn, pandas, and an ArcGIS pro license.\n",
    "\n",
    "Data sources: ACS-Survey 2014-2018 5-year Estimates, ACS-Survey 2015-2019 5-year Estimates, City of Minneapolis, U.S. Census Bureau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\msong\\Desktop\\Independent proj\\escooter_ML\\escooter_all.csv\"\n",
    "cols = ['GISJOIN', \n",
    "        'year', \n",
    "        'SUM_TripCount', \n",
    "        'percent_nonwhite',\n",
    "       'percent_hsandabv', \n",
    "        'medhhinc_normal',\n",
    "       'popdens_sqmi']\n",
    "#        'med_hh_inc']\n",
    "df = pd.read_csv(file_path,usecols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df that do not correspond with a census tract\n",
    "empty_df = df.loc[(df['GISJOIN'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset with no null vals\n",
    "data = df[df['GISJOIN'].notna()].drop('GISJOIN',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       232.000000\n",
       "mean       4097.737069\n",
       "std       13487.965540\n",
       "min           5.000000\n",
       "25%         121.250000\n",
       "50%         459.000000\n",
       "75%        2002.500000\n",
       "max      124153.000000\n",
       "Name: SUM_TripCount, dtype: float64"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['SUM_TripCount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pearson's correlation to see relationships between variables\n",
    "# ignore year correlation values\n",
    "corr = data.astype('float64').corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>SUM_TripCount</th>\n",
       "      <th>percent_nonwhite</th>\n",
       "      <th>percent_hsandabv</th>\n",
       "      <th>medhhinc_normal</th>\n",
       "      <th>popdens_sqmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.160063</td>\n",
       "      <td>0.008275</td>\n",
       "      <td>0.719022</td>\n",
       "      <td>0.049112</td>\n",
       "      <td>0.006367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUM_TripCount</th>\n",
       "      <td>0.160063</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.036318</td>\n",
       "      <td>0.130319</td>\n",
       "      <td>-0.098501</td>\n",
       "      <td>0.179049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_nonwhite</th>\n",
       "      <td>0.008275</td>\n",
       "      <td>-0.036318</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.526152</td>\n",
       "      <td>-0.683684</td>\n",
       "      <td>0.185241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percent_hsandabv</th>\n",
       "      <td>0.719022</td>\n",
       "      <td>0.130319</td>\n",
       "      <td>-0.526152</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.438344</td>\n",
       "      <td>-0.178517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medhhinc_normal</th>\n",
       "      <td>0.049112</td>\n",
       "      <td>-0.098501</td>\n",
       "      <td>-0.683684</td>\n",
       "      <td>0.438344</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.447139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>popdens_sqmi</th>\n",
       "      <td>0.006367</td>\n",
       "      <td>0.179049</td>\n",
       "      <td>0.185241</td>\n",
       "      <td>-0.178517</td>\n",
       "      <td>-0.447139</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      year  SUM_TripCount  ...  medhhinc_normal  popdens_sqmi\n",
       "year              1.000000       0.160063  ...         0.049112      0.006367\n",
       "SUM_TripCount     0.160063       1.000000  ...        -0.098501      0.179049\n",
       "percent_nonwhite  0.008275      -0.036318  ...        -0.683684      0.185241\n",
       "percent_hsandabv  0.719022       0.130319  ...         0.438344     -0.178517\n",
       "medhhinc_normal   0.049112      -0.098501  ...         1.000000     -0.447139\n",
       "popdens_sqmi      0.006367       0.179049  ...        -0.447139      1.000000\n",
       "\n",
       "[6 rows x 6 columns]"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into test and train set for validation\n",
    "# fracnum is the percentage\n",
    "fracNum = 0.30\n",
    "train_set = data.sample(frac = fracNum)\n",
    "test_set = data.drop(train_set.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input demographic fields of interest\n",
    "x_cols = ['percent_nonwhite',\n",
    "          'percent_hsandabv', \n",
    "          'medhhinc_normal',\n",
    "          'popdens_sqmi']\n",
    "# field to predict\n",
    "y_cols = 'SUM_TripCount'\n",
    "\n",
    "\n",
    "# indicate fields to be used in multilinear regression\n",
    "X_train = train_set[x_cols]\n",
    "y_train = train_set[y_cols]         \n",
    "\n",
    "# format test set\n",
    "X_test = test_set[x_cols]\n",
    "y_test = test_set[y_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.050158136719898216\n",
      "Testing score: 0.02782287541735995\n",
      "MAE of Linear Regression: 5396.486526471126 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run linear regression\n",
    "lin_reg = LinearRegression()\n",
    "_ = lin_reg.fit(X_train, y_train) # train regression with training set\n",
    "preds = lin_reg.predict(X_test) # predict values in test set\n",
    "\n",
    "print(\"Training score:\", lin_reg.score(X_train, y_train))\n",
    "print(\"Testing score:\", lin_reg.score(X_test, y_test))\n",
    "print(\"MAE of Linear Regression:\", mean_absolute_error(y_test, preds), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.0500130752943293\n",
      "Testing score: 0.0322975290094315\n",
      "MAE of Ridge Regression: 5355.170285914989 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# based on pearson's correlation, ridge is not a good method \n",
    "# because data is not have multicollinearity\n",
    "ridge = Ridge(alpha=0.1) # alpha can be altered\n",
    "_ = ridge.fit(X_train, y_train)\n",
    "preds = ridge.predict(X_test)\n",
    "\n",
    "print(\"Training score:\", ridge.score(X_train, y_train))\n",
    "print(\"Testing score:\", ridge.score(X_test, y_test))\n",
    "print(\"MAE of Ridge Regression:\", mean_absolute_error(y_test, preds), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Approach\n",
    "\n",
    "Note this approach was attempted before running Random Forest regression algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource: # https://www.datacamp.com/community/tutorials/random-forests-classifier-python\n",
    "clf=RandomForestClassifier(n_estimators=100,\n",
    "                           bootstrap=True,\n",
    "                           warm_start=True,\n",
    "                           max_features=\"sqrt\"\n",
    "                           # oob_score=True\n",
    "                           #min_samples_split=.1\n",
    "                           # random_state = 0\n",
    "                           #\n",
    "                          ) \n",
    "\n",
    "# Accuracy score will not compute anything when I have bootstrap set to True\n",
    "# Have tried reducing fields for random forest\n",
    "\n",
    "# Other factors tried:\n",
    "# warm_start=True\n",
    "# min_samples_split=10\n",
    "# random_state = 0\n",
    "\n",
    "_= clf.fit(X_train,y_train) # create branches and trees from training data\n",
    "y_pred=clf.predict(X_test) # predict values in test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)) # check accuracy score of test and train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.8726307058531736\n",
      "Testing score: 0.03695197469390088\n",
      "MAE of Random Forest Regression: 5109.405580246914 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run Random Forest Regressor\n",
    "rf_regr = RandomForestRegressor(n_estimators = 1000, random_state=0)\n",
    "_ = rf_regr.fit(X_train, y_train) # create trees in forest\n",
    "preds=rf_regr.predict(X_test) # predict values in test set\n",
    "\n",
    "print(\"Training score:\", rf_regr.score(X_train, y_train))\n",
    "print(\"Testing score:\", rf_regr.score(X_test, y_test))\n",
    "print(\"MAE of Random Forest Regression:\", mean_absolute_error(y_test, preds), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "resources:\n",
    "- about: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.PoissonRegressor.html\n",
    "- about_2: https://timeseriesreasoning.com/contents/poisson-regression-model/\n",
    "- tutorial: https://www.kaggle.com/gauravduttakiit/explore-the-poisson-regression\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# pr = PoissonRegressor()\n",
    "# pr.fit(X_train, y_train)\n",
    "# y_pr = pr.predict(X_test)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat table to include two fields:\n",
    "# year of dataset and total trip counts\n",
    "pdata = data[[\"year\",\"SUM_TripCount\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a training and test set\n",
    "train,test=train_test_split(pdata, train_size = .3,random_state =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape SUM_TripCount to be from a scale of -1 to 1\n",
    "X_train = train['SUM_TripCount'].values.reshape(-1, 1)\n",
    "y_train = train.year\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_scaled = scaler.transform(X_train)\n",
    "\n",
    "\n",
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape SUM_TripCount to be from a scale of -1 to 1\n",
    "X_test = test['SUM_TripCount'].values.reshape(-1, 1)\n",
    "y_test = test.year\n",
    "X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train regression and predict trip counts\n",
    "pipeline = Pipeline([('standardscaler', StandardScaler()),('model', PoissonRegressor())])\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "r2_test = metrics.r2_score(y_test, y_pred)\n",
    "r2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Notes: \n",
    "\n",
    "Documentation:\n",
    "<https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=random%20forest#sklearn.ensemble.RandomForestClassifier.score>\n",
    "\n",
    "- warm_start: bool, default=False\n",
    "When set to True, reuse the solution of the previous call to fit and \n",
    "add more estimators to the ensemble, otherwise, just fit a whole new forest. \n",
    "See the Glossary.\n",
    "\n",
    "- bootstrap : bool, default=True\n",
    "Whether bootstrap samples are used when building trees. \n",
    "If False, the whole dataset is used to build each tree.\n",
    "\n",
    "- max_features{“auto”, “sqrt”, “log2”}, int or float, default=”auto”\n",
    "The number of features to consider when looking for the best split:\n",
    "\n",
    "- random_state : int, RandomState instance or None, default=None\n",
    "Controls both the randomness of the bootstrapping of the samples used \n",
    "when building trees (if bootstrap=True) and the sampling of the \n",
    "features to consider when looking for the best split at each node \n",
    "(if max_features < n_features). See Glossary for details.\n",
    "\n",
    "- min_samples_leaf : int or float, default=1\n",
    "The minimum number of samples required to be at a leaf node. \n",
    "A split point at any depth will only be considered if it leaves at \n",
    "least min_samples_leaf training samples in each of the left and right \n",
    "branches. This may have the effect of smoothing the model, especially \n",
    "in regression.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
